{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn import svm\n",
    "import adversaries as ad\n",
    "from data_reader import input, output, operations\n",
    "from classifier_wrapper import Classifier\n",
    "from evasion_metrics import EvasionMetrics\n",
    "from copy import deepcopy\n",
    "\n",
    "#-----------------------------Library Demo---------------------------------\n",
    "# Demonstrate framework testing by simulating an SVM classifier and its  \n",
    "# resulting classification accuracy after an attack from the simple_optimize.py adversary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initial learner training:\n",
    "\n",
    "# choose a learning model \n",
    "learning_model = svm.SVC(probability=True, kernel='linear')\n",
    "\n",
    "# load the instances to feed to the learner and adversary \n",
    "instances = input.load_instances('./data_reader/data/test/100_instance_debug')\n",
    "\n",
    "# create a naive classifier using classifier_wrapper and specify the training data \n",
    "clf = Classifier(learning_model, instances)\n",
    "\n",
    "#train the classifier on the data\n",
    "clf.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Launch attack on the classifier using an AdversarialStrategy:\n",
    "\n",
    "# choose an adversary attack strategy, here we choose simple_optimize\n",
    "adv = ad.SimpleOptimize(lambda_val=-100, max_change = 65, learner = clf)\n",
    "\n",
    "# perform the attack/strategy on the data \n",
    "instances_post_attack = adv.attack(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# obtain metrics of classification performance both pre- and post- attack\n",
    "metrics = EvasionMetrics(clf, instances, instances_post_attack)\n",
    "preAccuracy = metrics.getAccuracy(True)\n",
    "postAccuracy = metrics.getAccuracy(False)\n",
    "print (\"Pre-attack Accuracy (naive classifier): \" + str(preAccuracy))\n",
    "print (\"Post-attack Accuracy: (naive classifier): \" + str(postAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot ROC curve of naive classifier performance after attack\n",
    "# currently the AUC is 1 because false positive rate is always in the demo case\n",
    "metrics.plotROC(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Learner responds by exercising a robust strategy when training:\n",
    "\n",
    "# create a robust classifier(classifier with an internal mechanism to protect against attack\n",
    "instances2 = input.load_instances('./data_reader/data/test/100_instance_debug')\n",
    "learning_model2 = svm.SVC(probability=True, kernel='linear')\n",
    "clf2 = Classifier(learning_model2, instances2, [\"retraining\", adv.clone()])\n",
    "#clf2.set_simulated_adversary_params({'lambda_val': -100, 'max_change': 65})\n",
    "clf2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we launch the attack on the robust classifier \n",
    "\n",
    "adv = ad.SimpleOptimize(lambda_val=-100, max_change = 65, learner = clf2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "instances_post_attack2 = adv.attack(instances2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# obtain metrics of classification performance both pre- and post- attack\n",
    "metrics2 = EvasionMetrics(clf2, instances, instances_post_attack2)\n",
    "preAccuracy2 = metrics2.getAccuracy(True)\n",
    "postAccuracy2 = metrics2.getAccuracy(False)\n",
    "print (\"Pre-attack Accuracy (robust classifier): \" + str(preAccuracy2))\n",
    "print (\"Post-attack Accuracy: (robust classifier): \" + str(postAccuracy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics2.plotROC(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
